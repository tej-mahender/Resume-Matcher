{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXBrquqABqdPJSr/YlN8Ee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tej-mahender/Resume-Matcher/blob/main/Notebook/LLM_Resume.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step - 1: Resume Ingestion**"
      ],
      "metadata": {
        "id": "n3MP-EbNSZFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (run once in Colab)\n",
        "!pip install PyPDF2 python-docx pytesseract pdf2image Pillow\n",
        "!apt-get install -y poppler-utils tesseract-ocr"
      ],
      "metadata": {
        "id": "-J9XywuTObE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "2sFlAollOdtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Extraction Functions ------------------\n",
        "def extract_text_from_pdf(file_path):\n",
        "    \"\"\"Try PyPDF2 first; fallback to OCR if text is empty.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(\"PyPDF2 extraction error:\", e)\n",
        "\n",
        "    # Fallback to OCR if PyPDF2 failed or returned empty\n",
        "    if not text.strip():\n",
        "        print(\"PyPDF2 failed or empty text, using OCR...\")\n",
        "        text = ocr_pdf(file_path)\n",
        "    return text\n",
        "\n",
        "def ocr_pdf(file_path):\n",
        "    \"\"\"Use pdf2image + pytesseract to extract text from scanned PDFs.\"\"\"\n",
        "    text = \"\"\n",
        "    pages = convert_from_path(file_path)\n",
        "    for page in pages:\n",
        "        page_text = pytesseract.image_to_string(page)\n",
        "        text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    try:\n",
        "        doc = docx.Document(file_path)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(\"Error reading DOCX:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_txt(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()"
      ],
      "metadata": {
        "id": "i2YupalfOZDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Normalization ------------------\n",
        "def normalize_text(text):\n",
        "    \"\"\"Clean and normalize resume text.\"\"\"\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Replace multiple spaces/tabs/newlines with a single space\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # Keep alphanumeric and common tech symbols (+, #, .)\n",
        "    text = re.sub(r\"[^a-z0-9+.# ]\", \"\", text)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "GxaNLie5OswM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Normalization ----------\n",
        "def normalize_text_readable(text):\n",
        "    \"\"\"\n",
        "    Normalize text for NLP while keeping readable line breaks.\n",
        "    \"\"\"\n",
        "    lines = text.split(\"\\n\")\n",
        "    normalized_lines = []\n",
        "    for line in lines:\n",
        "        line = line.strip().lower()                 # lowercase\n",
        "        line = re.sub(r\"\\s+\", \" \", line)           # collapse extra spaces\n",
        "        line = re.sub(r\"[^a-z0-9+.# ]\", \"\", line) # keep tech symbols\n",
        "        if line:                                   # skip empty lines\n",
        "            normalized_lines.append(line)\n",
        "    return \"\\n\".join(normalized_lines)"
      ],
      "metadata": {
        "id": "OLmBwXrtRaeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Main Extraction Function ------------------\n",
        "def extract_resume_text(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        raw_text = extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        raw_text = extract_text_from_docx(file_path)\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        raw_text = extract_text_from_txt(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Use PDF, DOCX, or TXT.\")\n",
        "\n",
        "    # normalized_text = normalize_text(raw_text)\n",
        "    normalized_text = normalize_text_readable(raw_text)\n",
        "\n",
        "    # ------------------ Debug / Output ------------------\n",
        "    print(f\"--- Extraction Complete for {file_path} ---\")\n",
        "    print(f\"Original Length: {len(raw_text)} chars | Normalized Length: {len(normalized_text)} chars\\n\")\n",
        "    print(\"------ FULL NORMALIZED TEXT ------\\n\")\n",
        "    print(normalized_text)\n",
        "\n",
        "    return normalized_text"
      ],
      "metadata": {
        "id": "dKKezFGbOuw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/TejMahendraResume.pdf\"  # upload your resume here\n",
        "    resume_text = extract_resume_text(file_path)   # Step 1"
      ],
      "metadata": {
        "id": "cOjlnwhuco8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step - 2 : Section Segmentation**"
      ],
      "metadata": {
        "id": "8soqNN66BVuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "gn5mTn8JBvVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Load Embedding Model ----------\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # lightweight, free, runs on CPU/GPU"
      ],
      "metadata": {
        "id": "_OaSUrc3BxBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Canonical section headers\n",
        "SECTION_HEADERS = {\n",
        "    \"skills\": [\"skills\", \"technical skills\", \"core skills\", \"technologies\"],\n",
        "    \"education\": [\"education\", \"academics\", \"qualifications\", \"academic background\", \"studies\", \"academic qualications\"],\n",
        "    \"experience\": [\"experience\", \"work experience\", \"employment history\", \"professional background\", \"work history\", \"internship\"],\n",
        "    \"projects\": [\"projects\", \"academic projects\", \"personal projects\", \"research work\"],\n",
        "    \"certifications\": [\"certifications\", \"licenses\", \"achievements\", \"awards\", \"training\", \"courses\"],\n",
        "    \"responsibilities\": [\"positions of responsibility\", \"leadership\", \"roles\", \"activities\"]\n",
        "}\n",
        "\n",
        "\n",
        "# Pre-compute embeddings for canonical headers\n",
        "canonical_labels = []\n",
        "canonical_texts = []\n",
        "for section, variations in SECTION_HEADERS.items():\n",
        "    for v in variations:\n",
        "        canonical_labels.append(section)\n",
        "        canonical_texts.append(v)\n",
        "\n",
        "canonical_embeddings = model.encode(canonical_texts, convert_to_tensor=True)\n",
        "\n",
        "# ---------- Hybrid Segmentation ----------\n",
        "def segment_resume_hybrid(text, similarity_threshold=0.6):\n",
        "    \"\"\"\n",
        "    Hybrid method: regex first, then embedding similarity for unknown headings.\n",
        "    \"\"\"\n",
        "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
        "    sections = {}\n",
        "    current_section = \"general\"\n",
        "\n",
        "    for line in lines:\n",
        "        line_lower = line.strip().lower()\n",
        "        found_heading = False\n",
        "\n",
        "        # --- Step 1: Regex match ---\n",
        "        for key, variations in SECTION_HEADERS.items():\n",
        "            if any(re.fullmatch(v, line_lower) for v in variations):\n",
        "                current_section = key\n",
        "                sections[current_section] = []\n",
        "                found_heading = True\n",
        "                break\n",
        "\n",
        "        # --- Step 2: Embedding similarity if no regex match ---\n",
        "        if not found_heading:\n",
        "            line_embedding = model.encode(line_lower, convert_to_tensor=True)\n",
        "            cosine_scores = util.cos_sim(line_embedding, canonical_embeddings)[0]\n",
        "            best_idx = int(cosine_scores.argmax())\n",
        "            best_score = float(cosine_scores[best_idx])\n",
        "\n",
        "            if best_score >= similarity_threshold:\n",
        "                current_section = canonical_labels[best_idx]\n",
        "                sections.setdefault(current_section, [])\n",
        "                found_heading = True\n",
        "\n",
        "        # --- Add line to current section ---\n",
        "        sections.setdefault(current_section, []).append(line)\n",
        "\n",
        "    return sections\n",
        "\n",
        "# ---------- Pretty Print ----------\n",
        "def print_sections(sections):\n",
        "    print(\"------ SEGMENTED RESUME (HYBRID) ------\\n\")\n",
        "    for section, content in sections.items():\n",
        "        print(f\"### {section.upper()} ###\")\n",
        "        for line in content:\n",
        "            print(f\"- {line}\")\n",
        "        print(\"\\n\")\n",
        "    print(\"------ END OF SEGMENTS ------\\n\")"
      ],
      "metadata": {
        "id": "DPQvXNEUBhdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/TejMahendraResume.pdf\"  # upload your resume here\n",
        "    sections = segment_resume_hybrid(resume_text)  # Step 2\n",
        "    print_sections(sections)\n",
        "\n"
      ],
      "metadata": {
        "id": "pNvdH8JWB2xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "import json\n",
        "\n",
        "# Ask for the API key safely (will not be displayed)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = input(\"🔑 Enter your Google API key: \").strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "uwgNKkLzFhkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# ---------- Initialize Gemini ----------\n",
        "# Initialize the client securely\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# ---------- Function to parse resume using Gemini ----------\n",
        "def parse_resume_with_gemini(resume_text):\n",
        "    prompt = f\"\"\"\n",
        "Extract a structured JSON from the resume text below.\n",
        "- Name\n",
        "- Email\n",
        "- Phone\n",
        "- Links (LinkedIn, GitHub, LeetCode, Portfolio if present)\n",
        "- Career Objective\n",
        "- Education (degree, institute, year, score/CGPA)\n",
        "- Skills (group by: languages, frontend, backend, databases, ML, cloud, tools)\n",
        "- Projects (title + description)\n",
        "- Certifications\n",
        "- Responsibilities\n",
        "\n",
        "Resume Text:\n",
        "{resume_text}\n",
        "\n",
        "Output strictly as JSON.\n",
        "\"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# ---------- Parse ----------\n",
        "structured_resume = parse_resume_with_gemini(resume_text)\n",
        "print(structured_resume)\n"
      ],
      "metadata": {
        "id": "m8H2fXXqWHAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step - 3 : JD ingestion**"
      ],
      "metadata": {
        "id": "FQBEm3HTSmUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from google import genai\n",
        "\n",
        "# ---------- Initialize Gemini Client ----------\n",
        "# Initialize the client securely\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# ---------- Function: Call Gemini and parse JD ----------\n",
        "def extract_jd_with_gemini(jd_text, model=\"gemini-2.5-flash\"):\n",
        "    \"\"\"\n",
        "    Parses a job description using Gemini LLM and returns structured JSON.\n",
        "    Handles triple backticks and malformed JSON gracefully.\n",
        "\n",
        "    Returns a Python dict with keys:\n",
        "    - education\n",
        "    - years_experience\n",
        "    - must_have_skills\n",
        "    - optional_skills\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Extract the following from the Job Description:\n",
        "- Required Education\n",
        "- Required Years of Experience\n",
        "- Must-have Skills\n",
        "- Optional Skills (good-to-have)\n",
        "\n",
        "Output strictly as JSON with keys:\n",
        "education, years_experience, must_have_skills, optional_skills\n",
        "\n",
        "Job Description:\n",
        "{jd_text}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    raw_text = response.text.strip()\n",
        "\n",
        "    # ---------- Clean triple backticks or json code blocks ----------\n",
        "    cleaned_text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw_text, flags=re.DOTALL)\n",
        "    cleaned_text = re.sub(r\"^```\\s*|\\s*```$\", \"\", cleaned_text, flags=re.DOTALL)\n",
        "\n",
        "    # ---------- Parse JSON ----------\n",
        "    try:\n",
        "        jd_json = json.loads(cleaned_text)\n",
        "    except json.JSONDecodeError:\n",
        "        # Return raw text if JSON parsing fails\n",
        "        jd_json = {\"raw_output\": cleaned_text}\n",
        "\n",
        "    return jd_json\n",
        "\n",
        "# ---------- Example usage ----------\n",
        "job_description = \"\"\"\n",
        "Must-have\n",
        "2+ years of hands-on experience in programming languages such as C/C++, Java, JavaScript, NodeJS, Python, Groovy, or ReactJS.\n",
        "B. Tech in Computer Science from a reputed college.\n",
        "Excellent computer science fundamentals and a solid understanding of architecture, design, and performance.\n",
        "Working knowledge and experience with REST APIs and Kafka.\n",
        "A good understanding of object-oriented design and knowledge of product life cycles.\n",
        "Strong proficiency in version control systems (e.g., Git) and source code management practices.\n",
        "Experience with CI/CD tools (e.g., Jenkins) and build automation.\n",
        "Familiarity with configuration management tools (e.g., Ansible, Puppet, Chef) is a plus.\n",
        "Good-to-have\n",
        "Knowledge of databases such as MySQL, Postgres, Cassandra, Redis, MongoDB, Elastic Search, Spark.\n",
        "Experience with AI/ML/DL technologies and their applications.\n",
        "\"\"\"\n",
        "\n",
        "jd_structured = extract_jd_with_gemini(job_description)\n",
        "print(json.dumps(jd_structured, indent=2))\n"
      ],
      "metadata": {
        "id": "RQ8UDtiKTLPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step - 4 : Final Comparision**"
      ],
      "metadata": {
        "id": "v61JQRUTcTkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# Initialize the client securely\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "def evaluate_resume_with_gemini(resume_text, jd_text):\n",
        "    prompt = f\"\"\"\n",
        "You are a recruitment assistant. Compare the candidate's resume with the job description.\n",
        "\n",
        "Resume:\n",
        "{structured_resume}\n",
        "\n",
        "Job Description:\n",
        "{jd_structured}\n",
        "\n",
        "Tasks:\n",
        "1. Give an overall match score (0-100%).\n",
        "2. Give section-wise match scores (education, experience, skills, projects, certifications, responsibilities).\n",
        "3. List missing skills or experience per section.\n",
        "4. Provide actionable suggestions to improve the resume for this job.\n",
        "\n",
        "Output strictly as JSON with keys:\n",
        "overall_score, section_scores, missing_items, suggestions\n",
        "\"\"\"\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    return response.text\n",
        "\n",
        "# ---------- Call LLM ----------\n",
        "report_json = evaluate_resume_with_gemini(resume_text, job_description)\n",
        "print(report_json)\n"
      ],
      "metadata": {
        "id": "_P7VRPiCW_qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_resume_with_gemini(resume_text, jd_text):\n",
        "    prompt = f\"\"\"\n",
        "You are a recruitment assistant. Compare the candidate's resume with the job description.\n",
        "\n",
        "Resume:\n",
        "{resume_text}\n",
        "\n",
        "Job Description:\n",
        "{jd_text}\n",
        "\n",
        "Tasks:\n",
        "1. Give an overall match score (0-100%).\n",
        "2. Give section-wise match scores (education, experience, skills, projects, certifications, responsibilities).\n",
        "3. List missing skills or experience per section.\n",
        "4. Provide actionable suggestions to improve the resume for this job.\n",
        "\n",
        "Format your answer in this clean, readable structure (NOT JSON):\n",
        "\n",
        "**Overall Match Score:** X%\n",
        "\n",
        "### Section Scores\n",
        "| Section | Score (%) |\n",
        "|----------|------------|\n",
        "| Education | ... |\n",
        "| Experience | ... |\n",
        "| Skills | ... |\n",
        "| Projects | ... |\n",
        "| Certifications | ... |\n",
        "| Responsibilities | ... |\n",
        "\n",
        "---\n",
        "\n",
        "### Missing Items\n",
        "**Experience:**\n",
        "- ...\n",
        "\n",
        "**Skills:**\n",
        "- ...\n",
        "\n",
        "**Projects:**\n",
        "- ...\n",
        "\n",
        "**General / Explicit Mentions:**\n",
        "- ...\n",
        "\n",
        "---\n",
        "\n",
        "### Suggestions\n",
        "1. ...\n",
        "2. ...\n",
        "3. ...\n",
        "\n",
        "Keep the layout minimal, clean, and professional.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=prompt\n",
        "    )\n",
        "\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "ZzFgGW1FChT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Call LLM ----------\n",
        "report_json = evaluate_resume_with_gemini(resume_text, job_description)\n",
        "print(report_json)"
      ],
      "metadata": {
        "id": "aJjqycHaCsf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QfWsm8tEGd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}